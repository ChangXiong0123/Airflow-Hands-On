[2021-07-21 04:47:57,064] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: elasticsearch_dag.connections_to_es 2021-07-21T02:29:24.983986+00:00 [queued]>
[2021-07-21 04:47:57,105] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: elasticsearch_dag.connections_to_es 2021-07-21T02:29:24.983986+00:00 [queued]>
[2021-07-21 04:47:57,107] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-07-21 04:47:57,107] {taskinstance.py:1068} INFO - Starting attempt 1 of 1
[2021-07-21 04:47:57,108] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-07-21 04:47:57,127] {taskinstance.py:1087} INFO - Executing <Task(PostgresToElasticOperator): connections_to_es> on 2021-07-21T02:29:24.983986+00:00
[2021-07-21 04:47:57,131] {standard_task_runner.py:52} INFO - Started process 6661 to run task
[2021-07-21 04:47:57,150] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'elasticsearch_dag', 'connections_to_es', '2021-07-21T02:29:24.983986+00:00', '--job-id', '276', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/elasticsearch_dag.py', '--cfg-path', '/tmp/tmpqtz3befs', '--error-file', '/tmp/tmpjd1cmyv6']
[2021-07-21 04:47:57,157] {standard_task_runner.py:77} INFO - Job 276: Subtask connections_to_es
[2021-07-21 04:47:57,278] {logging_mixin.py:104} INFO - Running <TaskInstance: elasticsearch_dag.connections_to_es 2021-07-21T02:29:24.983986+00:00 [running]> on host airflowvm
[2021-07-21 04:47:57,428] {taskinstance.py:1280} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=elasticsearch_dag
AIRFLOW_CTX_TASK_ID=connections_to_es
AIRFLOW_CTX_EXECUTION_DATE=2021-07-21T02:29:24.983986+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-07-21T02:29:24.983986+00:00
[2021-07-21 04:47:57,453] {base.py:69} INFO - Using connection to: id: elasticsearch_default. Host: localhost, Port: 9200, Schema: http, Login: None, Password: None, extra: {}
[2021-07-21 04:47:57,478] {base.py:69} INFO - Using connection to: id: ***_default. Host: localhost, Port: 5432, Schema: , Login: , Password: ***, extra: {'cursor': 'realdictcursor'}
[2021-07-21 04:47:57,504] {taskinstance.py:1481} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1137, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/airflow/plugins/elasticsearch_plugin/operators/postgres_to_elastic.py", line 30, in execute
    with closing(pg.get_conn()) as conn:
  File "/home/airflow/sandbox/lib/python3.8/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/sandbox/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  password authentication failed for user "airflow"
FATAL:  password authentication failed for user "airflow"

[2021-07-21 04:47:57,510] {taskinstance.py:1524} INFO - Marking task as FAILED. dag_id=elasticsearch_dag, task_id=connections_to_es, execution_date=20210721T022924, start_date=20210721T044757, end_date=20210721T044757
[2021-07-21 04:47:57,567] {local_task_job.py:151} INFO - Task exited with return code 1
